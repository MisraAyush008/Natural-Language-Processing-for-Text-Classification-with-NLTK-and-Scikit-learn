{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NLP for Text Classification.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTNyU7HVupjn"
      },
      "source": [
        "## Natural Language Processing for Text Classification with NLTK and Scikit-learn\n",
        "\n",
        "\n",
        "### 1. Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kuWtPr_upjn"
      },
      "source": [
        "import sys\n",
        "import nltk\n",
        "import sklearn\n",
        "import pandas\n",
        "import numpy"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqxfIH5Aupjn"
      },
      "source": [
        "### 2. Load the Dataset\n",
        "\n",
        "Now that we have ensured that our libraries are installed correctly, let's load the data set as a Pandas DataFrame. Furthermore, let's extract some useful information such as the column information and class distributions. \n",
        "\n",
        "The data set we will be using comes from the UCI Machine Learning Repository.  It contains over 5000 SMS labeled messages that have been collected for mobile phone spam research. It can be downloaded from the following URL:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk3JhLpZverR",
        "outputId": "4e9db6a7-c69e-4d60-8621-dc7f391c5533",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afa634cb-bed7-4419-8a88-5f597d9545ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afa634cb-bed7-4419-8a88-5f597d9545ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SMSSpamCollection.csv to SMSSpamCollection.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Bs-y6Iupjn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the dataset of SMS messages\n",
        "df = pd.read_table('./SMSSpamCollection.csv', sep=',', encoding='Latin-1')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSr8a0Ru2K19"
      },
      "source": [
        "sms = df"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBVD-IVnupjn",
        "outputId": "a126a85b-83d6-47ab-cc5b-521620d52934"
      },
      "source": [
        "# print useful information about the dataset\n",
        "print(df.info())\n",
        "# print(df.head())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5571 entries, 0 to 5570\n",
            "Data columns (total 5 columns):\n",
            " #   Column                                                                                                           Non-Null Count  Dtype \n",
            "---  ------                                                                                                           --------------  ----- \n",
            " 0   ham                                                                                                              5571 non-null   object\n",
            " 1   Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  5571 non-null   object\n",
            " 2   Unnamed: 2                                                                                                       50 non-null     object\n",
            " 3   Unnamed: 3                                                                                                       12 non-null     object\n",
            " 4   Unnamed: 4                                                                                                       6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R8cWyD514FG",
        "outputId": "638f63e9-d160-4663-f05b-21105069fc7a"
      },
      "source": [
        "# print useful information about the dataset\n",
        "# print(df.info())\n",
        "\n",
        "df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
        "print(df.head())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "0   ham                      Ok lar... Joking wif u oni...                                                             \n",
            "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...                                                             \n",
            "2   ham  U dun say so early hor... U c already then say...                                                             \n",
            "3   ham  Nah I don't think he goes to usf, he lives aro...                                                             \n",
            "4  spam  FreeMsg Hey there darling it's been 3 week's n...                                                             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFRj6DF92rHF",
        "outputId": "30cd7510-55cd-41d0-e690-52e2444c1d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.columns = ['0', '1']\n",
        "# print(df.shape)\n",
        "print(df.head())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      0                                                  1\n",
            "0   ham                      Ok lar... Joking wif u oni...\n",
            "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "2   ham  U dun say so early hor... U c already then say...\n",
            "3   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "4  spam  FreeMsg Hey there darling it's been 3 week's n...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sny_Vf7n4R43",
        "outputId": "05ef854c-de10-4a0c-ea67-1d5888eff77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(df))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB9fDfvrupjo",
        "outputId": "161d5759-b3d5-42cc-b5bc-22b43fa02a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check class distribution\n",
        "classes = df['0']\n",
        "print(classes.value_counts())"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ham     4824\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlRdrjDtupjo"
      },
      "source": [
        "### 2. Preprocess the Data\n",
        "\n",
        "Preprocessing the data is an essential step in natural language process. In the following cells, we will convert our class labels to binary values using the LabelEncoder from sklearn, replace email addresses, URLs, phone numbers, and other symbols by using regular expressions, remove stop words, and extract word stems.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YQ-TUDwupjo",
        "outputId": "975d3260-b2fd-4555-a30c-b1f0791abe92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# convert class labels to binary values, 0 = ham and 1 = spam\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(classes)\n",
        "\n",
        "print(Y[:10])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 0 0 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkbVNelupjp",
        "outputId": "6588eb7e-7812-4cb7-e5ba-2658452f0e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# store the SMS message data\n",
        "text_messages = df['1']\n",
        "print(text_messages[:10])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                        Ok lar... Joking wif u oni...\n",
            "1    Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "2    U dun say so early hor... U c already then say...\n",
            "3    Nah I don't think he goes to usf, he lives aro...\n",
            "4    FreeMsg Hey there darling it's been 3 week's n...\n",
            "5    Even my brother is not like to speak with me. ...\n",
            "6    As per your request 'Melle Melle (Oru Minnamin...\n",
            "7    WINNER!! As a valued network customer you have...\n",
            "8    Had your mobile 11 months or more? U R entitle...\n",
            "9    I'm gonna be home soon and i don't want to tal...\n",
            "Name: 1, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doS29-4Kupjp"
      },
      "source": [
        "#### 2.1 Regular Expressions\n",
        "\n",
        "Some common regular expression metacharacters - copied from wikipedia\n",
        "\n",
        "**^**     Matches the starting position within the string. In line-based tools, it matches the starting position of any line.\n",
        "\n",
        "**.**     Matches any single character (many applications exclude newlines, and exactly which characters are considered newlines is flavor-, character-encoding-, and platform-specific, but it is safe to assume that the line feed character is included). Within POSIX bracket expressions, the dot character matches a literal dot. For example, a.c matches \"abc\", etc., but [a.c] matches only \"a\", \".\", or \"c\".\n",
        "\n",
        "**[ ]**    A bracket expression. Matches a single character that is contained within the brackets. For example, [abc] matches \"a\", \"b\", or \"c\". [a-z] specifies a range which matches any lowercase letter from \"a\" to \"z\". These forms can be mixed: [abcx-z] matches \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\", as does [a-cx-z].\n",
        "The - character is treated as a literal character if it is the last or the first (after the ^, if present) character within the brackets: [abc-], [-abc]. Note that backslash escapes are not allowed. The ] character can be included in a bracket expression if it is the first (after the ^) character: []abc].\n",
        "\n",
        "**[^ ]**   Matches a single character that is not contained within the brackets. For example, [^abc] matches any character other than \"a\", \"b\", or \"c\". [^a-z] matches any single character that is not a lowercase letter from \"a\" to \"z\". Likewise, literal characters and ranges can be mixed.\n",
        "\n",
        "**$**      Matches the ending position of the string or the position just before a string-ending newline. In line-based tools, it matches the ending position of any line.\n",
        "\n",
        "**( )**    Defines a marked subexpression. The string matched within the parentheses can be recalled later (see the next entry, \\n). A marked subexpression is also called a block or capturing group. BRE mode requires \\( \\).\n",
        "\n",
        "**\\n**     Matches what the nth marked subexpression matched, where n is a digit from 1 to 9. This construct is vaguely defined in the POSIX.2 standard. Some tools allow referencing more than nine capturing groups.\n",
        "\n",
        "**\\***     Matches the preceding element zero or more times. For example, ab*c matches \"ac\", \"abc\", \"abbbc\", etc. [xyz]* matches \"\", \"x\", \"y\", \"z\", \"zx\", \"zyx\", \"xyzzy\", and so on. (ab)* matches \"\", \"ab\", \"abab\", \"ababab\", and so on.\n",
        "\n",
        "**{m,n}**  Matches the preceding element at least m and not more than n times. For example, a{3,5} matches only \"aaa\", \"aaaa\", and \"aaaaa\". This is not found in a few older instances of regexes. BRE mode requires \\{m,n\\}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzwtMdS4upjp"
      },
      "source": [
        "# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
        "\n",
        "# Replace email addresses with 'email'\n",
        "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
        "                                 'emailaddress')\n",
        "\n",
        "# Replace URLs with 'webaddress'\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                  'webaddress')\n",
        "\n",
        "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
        "    \n",
        "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                  'phonenumbr')\n",
        "    \n",
        "# Replace numbers with 'numbr'\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF_7tb0oupjp"
      },
      "source": [
        "# Remove punctuation\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "# Replace whitespace between terms with a single space\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# Remove leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aXjlbcQupjp",
        "outputId": "1f333c38-6055-4f60-ebc5-d5ed77038940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# change words to lower case - Hello, HELLO, hello are all the same word\n",
        "processed = processed.str.lower()\n",
        "print(processed)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                 ok lar joking wif u oni\n",
            "1       free entry in numbr a wkly comp to win fa cup ...\n",
            "2             u dun say so early hor u c already then say\n",
            "3       nah i don t think he goes to usf he lives arou...\n",
            "4       freemsg hey there darling it s been numbr week...\n",
            "                              ...                        \n",
            "5566    this is the numbrnd time we have tried numbr c...\n",
            "5567                 will ì_ b going to esplanade fr home\n",
            "5568    pity was in mood for that so any other suggest...\n",
            "5569    the guy did some bitching but i acted like i d...\n",
            "5570                            rofl its true to its name\n",
            "Name: 1, Length: 5571, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcI3hpSupjp",
        "outputId": "70d0ff6a-5f5f-4944-9346-d30e9bf4df1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# remove stop words from text messages\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoFugckGupjp"
      },
      "source": [
        "# Remove word stems using a Porter stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    ps.stem(term) for term in x.split()))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lg-W8Qlupjp"
      },
      "source": [
        "### 3. Generating Features\n",
        "\n",
        "Feature engineering is the process of using domain knowledge of the data to create features for machine learning algorithms. In this project, the words in each text message will be our features.  For this purpose, it will be necessary to tokenize each word.  We will use the 1500 most common words as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eno5KW4Tupjp",
        "outputId": "d55ced83-4ed9-45d6-b47b-8f558d11e9e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "# create bag-of-words\n",
        "all_words = []\n",
        "\n",
        "for message in processed:\n",
        "    words = word_tokenize(message)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "        \n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzJJhjKZupjp",
        "outputId": "b0dc7f55-b7ce-4576-a5fa-ee00aa7d649b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print the total number of words and the 15 most common words\n",
        "print('Number of words: {}'.format(len(all_words)))\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 6488\n",
            "Most common words: [('numbr', 2628), ('u', 1192), ('call', 672), ('go', 452), ('get', 451), ('ur', 385), ('gt', 318), ('lt', 316), ('come', 301), ('ok', 292), ('åmoneysymbnumbr', 288), ('free', 284), ('know', 274), ('day', 273), ('love', 260)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIDKy2SAupjp"
      },
      "source": [
        "# use the 1500 most common words as features\n",
        "word_features = list(all_words.keys())[:1500]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW8qcQKnupjp",
        "outputId": "0b9b521b-c2e3-4acb-ac87-fa68218a01d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The find_features function will determine which of the 1500 word features are contained in the review\n",
        "def find_features(message):\n",
        "    words = word_tokenize(message)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[word] = (word in words)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Lets see an example!\n",
        "features = find_features(processed[0])\n",
        "for key, value in features.items():\n",
        "    if value == True:\n",
        "        print (key)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "lar\n",
            "joke\n",
            "wif\n",
            "u\n",
            "oni\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CfK0COlupjp"
      },
      "source": [
        "# Now lets do it for all the messages\n",
        "messages = zip(processed, Y)\n",
        "\n",
        "# define a seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed = seed\n",
        "#np.random.shuffle(messages)\n",
        "\n",
        "# call find_features function for each SMS message\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FtrE1mGupjp"
      },
      "source": [
        "# we can split the featuresets into training and testing datasets using sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "# split the data into training and testing datasets\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVxY8SaOupjp",
        "outputId": "21e7fc2d-955f-430a-d618-e5212436360d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4178\n",
            "1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAruM1-rupjp"
      },
      "source": [
        "### 4. Scikit-Learn Classifiers with NLTK\n",
        "\n",
        "Now that we have our dataset, we can start building algorithms! Let's start with a simple linear support vector classifier, then expand to other algorithms. We'll need to import each algorithm we plan on using from sklearn.  We also need to import some performance metrics, such as accuracy_score and classification_report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoYSFLWnupjp",
        "outputId": "e47c8d2c-70a0-4a2d-e21b-b40269e7032b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We can use sklearn algorithms in NLTK\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
        "\n",
        "# train the model on the training data\n",
        "model.train(training)\n",
        "\n",
        "# and test on the testing dataset!\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 98.27709978463747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrdEigMmupjp",
        "outputId": "19ebc35a-c8f4-4474-e5e2-82c62c5761fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Define models to train\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = zip(names, classifiers)\n",
        "\n",
        "for name, model in models:\n",
        "    nltk_model = SklearnClassifier(model)\n",
        "    nltk_model.train(training)\n",
        "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "    print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors Accuracy: 93.39554917444364\n",
            "Decision Tree Accuracy: 97.20028715003589\n",
            "Random Forest Accuracy: 98.42067480258436\n",
            "Logistic Regression Accuracy: 98.56424982053123\n",
            "SGD Classifier Accuracy: 98.27709978463747\n",
            "Naive Bayes Accuracy: 97.91816223977028\n",
            "SVM Linear Accuracy: 98.27709978463747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81eqfriWupjq",
        "outputId": "c3632204-4aed-4db0-a89c-fbbbea669dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Ensemble methods - Voting classifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = list(zip(names, classifiers))\n",
        "\n",
        "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
        "nltk_ensemble.train(training)\n",
        "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting Classifier: Accuracy: 98.27709978463747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-WMeg98upjq"
      },
      "source": [
        "# make class label prediction for testing set\n",
        "txt_features, labels = zip(*testing)\n",
        "\n",
        "prediction = nltk_ensemble.classify_many(txt_features)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6eb95QQupjq",
        "outputId": "a3bb19be-88d7-482a-8cf9-a73550065446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# print a confusion matrix and a classification report\n",
        "print(classification_report(labels, prediction))\n",
        "\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(labels, prediction),\n",
        "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
        "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1202\n",
            "           1       0.99      0.90      0.95       191\n",
            "\n",
            "    accuracy                           0.99      1393\n",
            "   macro avg       0.99      0.95      0.97      1393\n",
            "weighted avg       0.99      0.99      0.99      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>ham</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
              "      <th>ham</th>\n",
              "      <td>1201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>19</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            predicted     \n",
              "                  ham spam\n",
              "actual ham       1201    1\n",
              "       spam        19  172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    }
  ]
}